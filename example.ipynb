{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Add the cell_generator module to path\n",
    "sys.path.insert(0, '/home/lionb/cell_generator')\n",
    "\n",
    "# Import cell_generator modules\n",
    "from dataset import DataGen\n",
    "import global_vars as gv\n",
    "from mg_analyzer import analyze_th\n",
    "from utils import *\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13dae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file paths\n",
    "data_csv_path = \"/mnt/new_groups/assafza_group/assafza/lion_models_clean/train_test_list/Nuclear-envelope/test.csv\"\n",
    "model_path = \"/mnt/new_groups/assafza_group/assafza/lion_models_clean/models/mg_model_ne_13_05_24_1.0\"\n",
    "\n",
    "# Verify paths exist\n",
    "print(f\"Data CSV exists: {os.path.exists(data_csv_path)}\")\n",
    "print(f\"Model path exists: {os.path.exists(model_path)}\")\n",
    "\n",
    "# Load the CSV to check data\n",
    "data_df = pd.read_csv(data_csv_path)\n",
    "print(f\"\\nDataset shape: {data_df.shape}\")\n",
    "print(f\"Dataset columns: {data_df.columns.tolist()}\")\n",
    "print(f\"First few rows:\\n{data_df.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420933a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override global variables for Nuclear-envelope organelle\n",
    "gv.organelle = \"Nuclear-envelope\"\n",
    "gv.model_path = model_path\n",
    "gv.train_ds_path = data_csv_path\n",
    "gv.test_ds_path = data_csv_path\n",
    "\n",
    "# Set input and target channels\n",
    "gv.input = \"channel_signal\"\n",
    "gv.target = \"channel_target\"\n",
    "\n",
    "# Set model parameters\n",
    "gv.model_type = \"MG\"\n",
    "gv.batch_size = 4\n",
    "gv.patch_size = (32, 128, 128, 1)\n",
    "gv.number_epochs = 100\n",
    "\n",
    "# Display the updated global variables\n",
    "print(\"Updated global variables:\")\n",
    "print(f\"  organelle: {gv.organelle}\")\n",
    "print(f\"  model_path: {gv.model_path}\")\n",
    "print(f\"  model_type: {gv.model_type}\")\n",
    "print(f\"  batch_size: {gv.batch_size}\")\n",
    "print(f\"  patch_size: {gv.patch_size}\")\n",
    "print(f\"  input: {gv.input}\")\n",
    "print(f\"  target: {gv.target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aabb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from CSV file\n",
    "print(f\"Creating dataset from: {data_csv_path}\")\n",
    "print(f\"Using input column: '{gv.input}' and target column: '{gv.target}'\")\n",
    "\n",
    "# Create DataGen object for the test dataset\n",
    "test_dataset = DataGen(\n",
    "    data_csv_path,\n",
    "    input_col=gv.input,\n",
    "    target_col=gv.target,\n",
    "    batch_size=gv.batch_size,\n",
    "    num_batches=4,\n",
    "    patch_size=gv.patch_size,\n",
    "    min_precentage=0.0,\n",
    "    max_precentage=1.0,\n",
    "    augment=False,\n",
    "    norm_type=\"std\",\n",
    "    delete_cahce=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset created successfully!\")\n",
    "print(f\"Number of images in dataset: {len(test_dataset.list_of_image_keys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MaskInterpreter model\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "try:\n",
    "    model = keras.models.load_model(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "    print(f\"Model summary:\")\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analyze_th to generate predictions and importance masks\n",
    "# This function will:\n",
    "# 1. Generate predictions on original images\n",
    "# 2. Generate importance masks\n",
    "# 3. Apply thresholding at different levels\n",
    "# 4. Compute mask efficacy (PCC between predictions)\n",
    "# 5. Save visualizations and results\n",
    "\n",
    "print(\"Running analyze_th for predictions and importance mask generation...\")\n",
    "print(\"This may take a while depending on the dataset size...\")\n",
    "\n",
    "# Use only first 2 images for demonstration (use range(len(test_dataset.list_of_image_keys)) for all)\n",
    "num_images_to_analyze = 2\n",
    "images_to_analyze = range(min(num_images_to_analyze, len(test_dataset.list_of_image_keys)))\n",
    "\n",
    "try:\n",
    "    analyze_th(\n",
    "        dataset=test_dataset,\n",
    "        mode=\"regular\",  # Mode options: \"agg\", \"loo\", \"mask\", \"regular\"\n",
    "        manual_th=\"full\",  # Full importance mask without thresholding\n",
    "        save_image=True,  # Save visualizations\n",
    "        save_histo=False,  # Save importance mask histograms\n",
    "        weighted_pcc=False,  # Use regular PCC (not weighted)\n",
    "        model_path=model_path,\n",
    "        model=model,\n",
    "        compound=None,  # No compound/drug perturbation\n",
    "        images=images_to_analyze,  # Which images to analyze\n",
    "        noise_scale=1.5,  # Noise scale for perturbation\n",
    "        save_results=True,\n",
    "        results_save_path=None  # Will save in model_path/predictions/\n",
    "    )\n",
    "    print(\"analyze_th completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during analyze_th: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b95639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization function to display input, prediction, and explanation masks\n",
    "def visualize_results(dataset, image_index, model, patch_size, save_path=None):\n",
    "    \\\"\\\"\\\"\\\n",
    "    Visualize all channels of input image together with prediction and explanation mask.\n",
    "    \n",
    "    Args:\n",
    "        dataset: DataGen object\n",
    "        image_index: Index of image to visualize\n",
    "        model: Loaded MaskInterpreter model\n",
    "        patch_size: Patch size used by model\n",
    "        save_path: Optional path to save figure\n",
    "    \\\"\\\"\\\"\\\n",
    "    from cell_imaging_utils.datasets_metadata.table.datasetes_metadata_csv import DatasetMetadataSCV\n",
    "    from cell_imaging_utils.image.image_utils import ImageUtils\n",
    "    import cv2\n",
    "    \n",
    "    # Load image\n",
    "    print(f\"Loading image {image_index}...\")\n",
    "    image_row = dataset.get_image_row(image_index)\n",
    "    path_tiff = image_row[dataset.image_path_col]\n",
    "    \n",
    "    # Load input and target channels\n",
    "    input_image = ImageUtils.imread_tiff(path_tiff, image_row[dataset.input_col])\n",
    "    target_image = ImageUtils.imread_tiff(path_tiff, image_row[dataset.target_col])\n",
    "    \n",
    "    # Normalize\n",
    "    input_image = (input_image - np.mean(input_image)) / (np.std(input_image) + 1e-6)\n",
    "    target_image = (target_image - np.mean(target_image)) / (np.std(target_image) + 1e-6)\n",
    "    \n",
    "    print(f\"Input shape: {input_image.shape}, Target shape: {target_image.shape}\")\n",
    "    \n",
    "    # Get predictions and importance mask from model\n",
    "    print(\"Generating predictions and importance masks...\")\n",
    "    \n",
    "    # Process image in patches\n",
    "    from mg_analyzer import collect_patchs, predict, assemble_image\n",
    "    \n",
    "    center_xy = [312, 462]\n",
    "    margin = [192, 256]\n",
    "    xy_step = 64\n",
    "    z_step = 16\n",
    "    \n",
    "    px_start = center_xy[0] - margin[0] - xy_step\n",
    "    py_start = center_xy[1] - margin[1] - xy_step\n",
    "    pz_start = 0\n",
    "    px_end = center_xy[0] + margin[0] + xy_step\n",
    "    py_end = center_xy[1] + margin[1] + xy_step\n",
    "    pz_end = input_image.shape[0]\n",
    "    \n",
    "    # Collect patches\n",
    "    input_patchs = collect_patchs(px_start, py_start, pz_start, px_end, py_end, pz_end, \n",
    "                                  input_image, patch_size, xy_step, z_step)\n",
    "    \n",
    "    # Predict\n",
    "    predictions, importance_masks = predict(model, input_patchs, batch_size=4)\n",
    "    \n",
    "    # Assemble predictions and masks back to full image\n",
    "    pred_image = assemble_image(predictions, (pz_end-pz_start, px_end-px_start, py_end-py_start, 1),\n",
    "                                patch_size, xy_step, z_step)\n",
    "    mask_image = assemble_image(importance_masks, (pz_end-pz_start, px_end-px_start, py_end-py_start, 1),\n",
    "                                patch_size, xy_step, z_step)\n",
    "    \n",
    "    # Select middle z-slice for visualization\n",
    "    z_mid = input_image.shape[0] // 2\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = GridSpec(2, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Row 1: Input, Target, Prediction\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(input_image[z_mid, :, :, 0], cmap='viridis')\n",
    "    ax1.set_title('Input Signal')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(target_image[z_mid, :, :, 0], cmap='hot')\n",
    "    ax2.set_title('Target')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.imshow(pred_image[z_mid, :, :, 0], cmap='hot')\n",
    "    ax3.set_title('Prediction')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    # Row 2: Importance mask, Input overlay with mask, Prediction overlay with mask\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    im_mask = ax4.imshow(mask_image[z_mid, :, :, 0], cmap='cool')\n",
    "    ax4.set_title('Importance Mask')\n",
    "    ax4.axis('off')\n",
    "    plt.colorbar(im_mask, ax=ax4)\n",
    "    \n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    ax5.imshow(input_image[z_mid, :, :, 0], cmap='gray', alpha=0.7)\n",
    "    ax5.imshow(mask_image[z_mid, :, :, 0], cmap='Reds', alpha=0.4)\n",
    "    ax5.set_title('Input + Mask Overlay')\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    ax6.imshow(target_image[z_mid, :, :, 0], cmap='gray', alpha=0.7)\n",
    "    ax6.imshow(mask_image[z_mid, :, :, 0], cmap='Reds', alpha=0.4)\n",
    "    ax6.set_title('Target + Mask Overlay')\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Image {image_index} - Z-slice {z_mid}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Figure saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return pred_image, mask_image\n",
    "\n",
    "print(\"Visualization function created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4daa6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results for the first image\n",
    "if model is not None and len(test_dataset.list_of_image_keys) > 0:\n",
    "    try:\n",
    "        pred_image, mask_image = visualize_results(\n",
    "            dataset=test_dataset,\n",
    "            image_index=0,\n",
    "            model=model,\n",
    "            patch_size=gv.patch_size,\n",
    "            save_path=None  # Set to a path to save figure, e.g., \"/tmp/prediction_viz.png\"\n",
    "        )\n",
    "        print(\"Visualization completed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during visualization: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"Model not loaded or no images available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eda4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display results from analyze_th\n",
    "results_dir = f\"{model_path}/predictions\"\n",
    "\n",
    "if os.path.exists(results_dir):\n",
    "    print(f\"Results directory: {results_dir}\")\n",
    "    \n",
    "    # Check for results CSV files\n",
    "    pcc_results_path = f\"{results_dir}/pcc_resuls.csv\"\n",
    "    mask_size_results_path = f\"{results_dir}/mask_size_resuls.csv\"\n",
    "    \n",
    "    if os.path.exists(pcc_results_path):\n",
    "        pcc_results = pd.read_csv(pcc_results_path)\n",
    "        print(\"\\nPCC Results (Mask Efficacy):\")\n",
    "        print(pcc_results)\n",
    "    \n",
    "    if os.path.exists(mask_size_results_path):\n",
    "        mask_size_results = pd.read_csv(mask_size_results_path)\n",
    "        print(\"\\nMask Size Results:\")\n",
    "        print(mask_size_results)\n",
    "    \n",
    "    # List generated images\n",
    "    print(f\"\\nGenerated files in {results_dir}:\")\n",
    "    for item in os.listdir(results_dir):\n",
    "        item_path = os.path.join(results_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"  [DIR] {item}\")\n",
    "        else:\n",
    "            print(f\"  [FILE] {item}\")\n",
    "else:\n",
    "    print(f\"Results directory not found: {results_dir}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
